[toc]

# 基本概念


## 协方差

>   衡量两个变量的总体误差
>   协方差表示的是两个变量的总体的误差，这与只表示一个变量误差的方差不同。

- 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 

- 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。

期望值分别为E[X]与E[Y]的两个实随机变量X与Y之间的协方差Cov(X,Y)定义为：

![img](https://bkimg.cdn.bcebos.com/formula/32ab8c25259851a89027c916cc506e27.svg)

## 相关系数

>较为常用的是皮尔逊相关系数，研究变量之间线性相关程度的量，一般用字母 r 表示。

- 相关系数是用以反映变量之间相关关系密切程度的统计指标。
- 相关系数按积差方法计算，同样以两变量与各自平均值的离差为基础，通过两个离差相乘来反映两变量之间相关程度。
	- .00-.19 “very weak”
   	- .20-.39 “weak”
   	- .40-.59 “moderate”
    - .60-.79 “strong”
   	- .80-1.0 “very strong” 	

![img](https://bkimg.cdn.bcebos.com/formula/565d6ddbd305158d2e80faf420df4417.svg)

Cov(X,Y)为X与Y的协方差，Var[X]为X的方差，Var[Y]为Y的方差

## logloss
```python
log_loss(y_true, y_pred)
# 越小越好
```
### Binary Classification

In binary classification (M=2), the formula equals:

![-{(y\log(p) + (1 - y)\log(1 - p))}](http://wiki.fast.ai/images/math/a/4/6/a4651d4ad311666c617d57c1dde37b28.png)



### Multi-class Classification

In multi-class classification (M>2), we take the sum of log loss values for each class prediction in the observation.

![-\sum_{c=1}^My_{o,c}\log(p_{o,c})](http://wiki.fast.ai/images/math/8/a/a/8aa1e513366a2046bee816f7a0f8dd1c.png)



![Log loss graph.png](http://wiki.fast.ai/images/4/43/Log_loss_graph.png)